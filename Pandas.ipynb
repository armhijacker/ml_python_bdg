{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Dive into Pandas World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what a typical data science project looks like:\n",
    "1. Problem identification\n",
    "2. **EDA**\n",
    "3. **Data Cleaning**\n",
    "4. **Feature Engineering**\n",
    "5. Modeling\n",
    "6. Project Delivery \n",
    "\n",
    "During this class we will discuss and work on 2, 3 and 4 points from the list above with Pandas.\n",
    "\n",
    "### Exploratory Data Analysis:\n",
    "\n",
    "*“Exploratory data analysis” is an attitude, a state of flexibility, a willingness to look for those things that we believe are not there, as well as those we believe to be there.*\n",
    "<br>\n",
    "— John Tukey\n",
    "<br> \n",
    "<br>\n",
    "During EDA, we use plots, graphs, and summary statistics to gain more understanding and intuition about the dataset. \n",
    "<br>\n",
    "<br>\n",
    "Generally speaking, it’s a method of systematically going through the data, plotting distributions of all variables (using box plots), plotting time series of data, transforming variables, looking at all pairwise relationships between variables using scatterplot matrices, and generating summary statistics for all of them. [1]\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**A simple guide to help you conduct EDA:**\n",
    "1. Dataset overview\n",
    "    - Exploring summary statistics of variables\n",
    "    - Exploring NAs\n",
    "2. Going deeper by examining each variable individually\n",
    "    - Visualisation of each variable \n",
    "    - Outlier detection\n",
    "3. Exploring the interaction of two or more variables\n",
    "    - Visualisation techniques\n",
    "    - Correlation matrices \n",
    "\n",
    "<br>\n",
    "\n",
    "**How to clean up a dataset:**  \n",
    "1. Dealing with unuseful data\n",
    "2. Dealing with NAs\n",
    "3. Dealing with outliers\n",
    "4. Dealing with Duplicates\n",
    "\n",
    "<br>\n",
    "\n",
    "**Creating new features with Feature Engineering:**\n",
    "1. Many new variables from datetime objects\n",
    "2. Changing data type (e.g. continuous to categorical)\n",
    "3. Creating dummy variables\n",
    "4. Creating new variables using the sum, product, difference of two or more variables\n",
    "5. Using your imagination for more \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Further you can find application to the methods and techniques described above. This is a general EDA and preprocessing analysis that can be used later for modeling. \n",
    "\n",
    "[Link to dataset](https://www.kaggle.com/carrie1/ecommerce-data):\n",
    "\n",
    "\n",
    "\"This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import date\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.csv'\n",
    "folder = 'data'\n",
    "path = os.path.join(folder, filename)\n",
    "# path = 'data/InvoiceData.csv'\n",
    "data = pd.read_csv(path, encoding='unicode-escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Top and Buttom n elements\n",
    "# data.head() \n",
    "# data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Info About Data types\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the main statistics of your data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Checking missig values\\n {data.isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Checking for duplicates values\\n {data.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <div align=\"center\">  Metadata </div>        \n",
    "\n",
    "| **Column Name** |     **Description**  |  \n",
    "|----------       |:-------------:       |\n",
    "| InvoiceNo       |  Invoice Number      |\n",
    "| StockCode       |  Product code        |\n",
    "| Description     |  Product description |\n",
    "| Quantity        |  Number of purchased items |\n",
    "| InvoiceDate     |  Invoice Date        |\n",
    "| UnitPrice       |  Price for one item  |\n",
    "| CustomerID      |  Customer ID         |\n",
    "| Country         |  Customer's country  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information about dataset\n",
    "# print(type(data.CustomerID.values))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types\n",
    "# data.InvoiceDate == data['InvoiceDate']\n",
    "data['InoviceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "data['CustomerID'] = data['CustomerID'].astype(str)# astype('O'|str|int|float...)\n",
    "# data.InvoiceNo.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(exclude='O') # include='O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Slicing example\n",
    "focus_columns = ['Quantity', 'InvoiceDate']\n",
    "data[focus_columns][:2000]\n",
    "\n",
    "# data.loc[:2000, 'Quantity']\n",
    "# data.iloc[:2000, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create a DataFrame from Scratch\n",
    "DD = {\"A\": [1,2,3,4,5], \"N\": [8,9,10,11,12]}\n",
    "pd.DataFrame(DD).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Dealing with NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NAs and Percentage of NAs in dataset\n",
    "# data.shape -> (i, j)\n",
    "data_nas = pd.DataFrame(data.isna().sum(), columns=['Number of NAs'])\n",
    "data_nas['Percentage of NAs'] = round(data_nas['Number of NAs'] / data.shape[0] * 100, 3)\n",
    "data_nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this EDA and future analysis is to understand the behavior of company customers, which is why we need to remove NAs in 'CustomerID' column. Moreover, by removing these values from 'Customer ID' we clean 'Description' NAs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead we can drop columns CustomerID and Description\n",
    "# data = data[['InvoiceNo', 'StockCode', 'Quantity', 'InvoiceDate',\n",
    "#        'UnitPrice', 'Country']]\n",
    "data.dropna(subset=['CustomerID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Be Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring each variable separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numbers of observations: \", data.shape[0])\n",
    "# print(\"Numbers of unique invoices: \", data.InvoiceNo.nunique())\n",
    "# print('Number of unique customers: ', data.CustomerID.nunique())\n",
    "print('Numbere of unique products:', data.StockCode.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    print(f\"Column name:{i}\",\n",
    "          \"\\nUnique values: \", data[i].unique(),\n",
    "          \"\\nNumber of unique values: \", data[i].nunique(), \"\\n____\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the huge difference between number of observations and numbers of unique orders, which means that database has no order level structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continuous data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.distplot(data.Quantity)\n",
    "plt.axvline(data.Quantity.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(data.Quantity.median(), color='r', linewidth=1)\n",
    "plt.title('Distribution of variable \"Quantity\"')\n",
    "plt.xlabel(\"Quantity\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5)) \n",
    "sns.distplot(data.UnitPrice)\n",
    "plt.axvline(data.UnitPrice.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(data.UnitPrice.median(), color='r', linewidth=1)\n",
    "plt.title('Distribution of variable \"UnitPrice\"')\n",
    "plt.xlabel(\"UnitPrice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x=data.InvoiceDate[:10000], y=data.Quantity[:10000]) # Boxplot\n",
    "plt.xticks(rotation = 70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the above graphs show that we have outliers for both variables. We will explore them more deeply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime variable\n",
    "data['InvoiceDate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In analyzing customer behavior, date and time variables will play a major role in solving various types of problems. This will be useful later in the analysis of retention, loyalty, segmentation, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With continuous - Histpgram , with categorical -  Barplot \n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data.Country) # Barplot \n",
    "plt.title('Frequency of variable \"Country\"')\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Frequency in each class\")\n",
    "plt.xticks(rotation = 70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most customers are based in UK. From the point of view of the 'Country' variable, the data is highly imbalanced.\n",
    "<br>\n",
    "<br>\n",
    "There is no need to visualize other categorical variables, because these variables have many unique values and we can't gain any valuable information from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Quantity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.UnitPrice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring large values  of 'UnitPrice' variable\n",
    "larges = data[data['UnitPrice']>=500] # .loc but it's not that beautiful \n",
    "sns.scatterplot(data=larges,x='UnitPrice', y='Quantity')\n",
    "plt.title('Scatterplot of \"Unit Price\" and \"Quantity\"')\n",
    "plt.xlabel(\"Unit Price\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at categorical variables of this part of the data once again\n",
    "larges.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values of 'StockCode' variable.\n",
    "larges.StockCode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values of 'Description' variable.\n",
    "# larges.Description.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some assumptions:**\n",
    "1. From the plot above and from the description of the 'Quantity' variable, it is clear that we have a lot of data issues. First of all, the quantity variable cannot take a negative value. Moreover, our maximum value is very large. It is doubtful that a customer can buy the same product so many times. \n",
    "<br>\n",
    "<br>\n",
    "2. Next variable with outliers is 'UnitPrice'. The only problem with this is the very large values.To understand the reasons for their occurrence, we only consider observations at unit prices of 500 or more. Some interesting relations can be found:\n",
    "    <br>\n",
    "    2.1 High unit prices mostly have negative values for the Quantity variable. \n",
    "    <br>\n",
    "    2.2 The variables 'StockCode 'and' Description 'show that these observations are basically not ordinary products.  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**What to do next:**\n",
    "1. Remove negative and very large values from 'Quantity' variable.\n",
    "2. Remove StockCode and Description values which do not apply to usual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative values from 'Quantity' variable and very large values of 'Quantity' variable\n",
    "filtered = data[data['Quantity'] >= 0]\n",
    "filtered = filtered[filtered['Quantity']<5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove not real product codes from StockCode and very large values of 'Unit Price' variable\n",
    "vals = ['M', 'D', 'POST',  'DOT', 'CRUK']\n",
    "filtered = filtered[~filtered['StockCode'].isin(vals)] # Syntactic Suger sample\n",
    "\n",
    "filtered = filtered[filtered['UnitPrice']<500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(filtered.Quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST IT IN REGRESSION\n",
    "# sparse vector proble \n",
    "weekday = filtered.InvoiceDate.dt.weekday.astype('category')\n",
    "country = filtered.Country.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new variables will help to find more relations in data. They may be used in later analysis as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['TotalPrice'] = filtered['Quantity'] * filtered['UnitPrice']\n",
    "filtered['OrderHour'] = filtered.InvoiceDate.dt.hour\n",
    "filtered['OrderMonth'] = filtered.InvoiceDate.dt.month\n",
    "filtered['OrderWeekday'] = filtered.InvoiceDate.dt.weekday\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.to_csv(\"data/data_cleared.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exploring interaction of two or more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Quantity', \"UnitPrice\", 'TotalPrice', 'OrderHour', 'OrderMonth']\n",
    "# It may take long time to process\n",
    "# sns.pairplot(filtered, vars = num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = filtered.select_dtypes(exclude=\"O\").corr()\n",
    "\n",
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, annot=corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only relationship we can find is between Quantity and Total price, which has an obvious reason: TotalPrice was created from multiplying Quantity and Unit prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=filtered[\"OrderWeekday\"], y=filtered[\"Quantity\"] )\n",
    "plt.title('Barplot of \"OrderWeekday\" and \"Quantity\" variables')\n",
    "plt.xlabel(\"Variable 'OrderWeekday'\")\n",
    "plt.ylabel(\"Variable 'Quantity'\")\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=filtered[\"OrderMonth\"],y=filtered[\"Quantity\"] )\n",
    "plt.title('Barplot of \"OrderMonth\" and \"Quantity\" variables')\n",
    "plt.xlabel(\"Variable 'OrderMonth'\")\n",
    "plt.ylabel(\"Variable 'Quantity'\")\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=filtered[\"OrderHour\"], y=filtered[\"Quantity\"] )\n",
    "plt.title('Barplot of \"OrderHour\" and \"Quantity\" variables')\n",
    "plt.xlabel(\"Variable 'OrderHour'\")\n",
    "plt.ylabel(\"Variable 'Quantity'\")\n",
    "plt.xticks(rotation=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation between time variables and 'Quantity' variable:\n",
    "\n",
    "- Minimum order quantity reached on Sunday.\n",
    "- November has the least quantity of ordered products. \n",
    "- Customers usually make purchases at 7am."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "This is just an example of EDA and data preprocessing that you can conduct. You can dig deeper, find more relationships, add more data and everything you can think of. This is an art and you're the master!\n",
    "\n",
    "More importantly, this is just the beginning. We will use this data, knowledge and intuition, which we obtained as a result of this analysis, to go further and solve many problems related to customer behavior.\n",
    "\n",
    "**Further Reading**\n",
    "<br>\n",
    "[1] [Doing Data Science](https://www.oreilly.com/library/view/doing-data-science/9781449363871/)\n",
    "<br>\n",
    "[2] [R for Marketing Research and Analytics](https://www.springer.com/gp/book/9783030143152)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
